name: Daily Scrape

on:
  schedule:
    - cron: "0 7 * * *"  # Runs every day at 07:00 UTC. 
                         # Change as needed. Format is min hour day-of-month month day-of-week
  workflow_dispatch:     # Allows you to manually trigger this from the Actions tab if you want
jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Check out code
        uses: actions/checkout@v2

      - name: Install Chrome
        run: |
          sudo apt-get update
          sudo apt-get install -y wget gnupg
          wget https://dl.google.com/linux/linux_signing_key.pub
          sudo apt-key add linux_signing_key.pub
          echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.9"   

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Scraper
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: "us-east-1"  
        run: |
          python scrape.py
